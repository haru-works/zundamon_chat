import streamlit as st
import tempfile
import os
import soundfile as sf
import base64
import time
from pydantic import SecretStr

# langchain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage,SystemMessage

# æ–‡ç« åˆ†å‰²
import functools
from ja_sentence_segmenter.common.pipeline import make_pipeline
from ja_sentence_segmenter.concatenate.simple_concatenator import concatenate_matching
from ja_sentence_segmenter.normalize.neologd_normalizer import normalize
from ja_sentence_segmenter.split.simple_splitter import split_newline, split_punctuation
from sentence_splitter import SentenceSplitter

import sys

# è¿½åŠ 
import nltk
nltk.download('averaged_perceptron_tagger')
nltk.download('averaged_perceptron_tagger_eng')


# ç’°å¢ƒå¤‰æ•°ã®èª­è¾¼
from dotenv import load_dotenv
load_dotenv()


current_dir = os.path.dirname(os.path.abspath(__file__))
repo_root = os.path.dirname(current_dir)
sys.path.insert(0, repo_root)
sys.path.insert(0, current_dir)
sys.path.append(os.path.join(current_dir, 'GPT_SoVITS'))

# æ¨è«–é–¢æ•°ã¨å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ï¼ˆå¿…è¦ã«å¿œã˜ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’èª¿æ•´ã—ã¾ã™ï¼‰
from tools.i18n.i18n import I18nAuto
from GPT_SoVITS.inference_webui import change_gpt_weights, change_sovits_weights, get_tts_wav

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä¿®æ­£ã—ã¾ã—ãŸï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
GPT_MODEL_PATH =  os.path.join(current_dir, 'GPT_weights_v2', 'zudamon_style_1-e15.ckpt')
SOVITS_MODEL_PATH = os.path.join(current_dir, 'SoVITS_weights_v2', 'zudamon_style_1_e8_s96.pth')

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# session_stateã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ã€å†å®Ÿè¡Œã®ã‚¯ãƒªã‚¢ã‚’é˜²ã
if "audio_bytes" not in st.session_state:
    st.session_state.audio_bytes = []


# æ¨è«–é–¢æ•°ã‚’å®šç¾©
def synthesize(ref_audio_path, ref_text_path, ref_language, target_text_path, target_language, output_path):

    # å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã‚“ã§ãã ã•ã„
    with open(ref_text_path, 'r', encoding='utf-8') as file:
        ref_text = file.read()

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã‚“ã§ãã ã•ã„
    with open(target_text_path, 'r', encoding='utf-8') as file:
        target_text = file.read()

    # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿å¤‰æ›´ã—
    change_gpt_weights(gpt_path=GPT_MODEL_PATH)
    change_sovits_weights(sovits_path=SOVITS_MODEL_PATH)

    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ç”Ÿæˆã—ã¾ã™
    synthesis_result = get_tts_wav(ref_wav_path=ref_audio_path,
                                   prompt_text=ref_text,
                                   prompt_language=ref_language,
                                   text=target_text,
                                   text_language=target_language,
                                   top_p=0.6,
                                   temperature=0.6)

    result_list = list(synthesis_result)

    if result_list:
        last_sampling_rate, last_audio_data = result_list[-1]
        output_wav_path = os.path.join(output_path, "output.wav")
        sf.write(output_wav_path, last_audio_data, last_sampling_rate)
        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_wav_path}")


# llmåˆæœŸåŒ–
def init_llm(llm_model: str):
    if llm_model == 'gemini-1.5-flash' or llm_model == 'gemini-2.0-flash':
        return ChatGoogleGenerativeAI(model=llm_model,
                                      api_key=SecretStr(os.getenv('GOOGLE_API_KEY')),
                                      temperature=1.0,)
    else:
        st.error(f'ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ãªã„LLMãƒ¢ãƒ‡ãƒ«ãªã®ã : {llm_model}',icon="âœ–")



# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# session_stateã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ã€å†å®Ÿè¡Œã®ã‚¯ãƒªã‚¢ã‚’é˜²ã
if "audio_bytes" not in st.session_state:
    st.session_state.audio_bytes = []


# éŸ³å£°å†ç”Ÿ
def play_audio(output_wav_path,assistant_avatar,sentences):
    with open(output_wav_path, "rb") as fw:
        audio_bytes_data = fw.read()
        fw.close()
        audio_placeholder = st.empty()
        audio_str = "data:audio/ogg;base64,%s"%(base64.b64encode(audio_bytes_data).decode())
        audio_html = f"""
                        <audio autoplay=True>
                        <source src={audio_str} type="audio/ogg" autoplay=True>
                        Your browser does not support the audio element.
                        </audio>
                    """
        audio_placeholder.empty()
        time.sleep(0.5)
        audio_placeholder.markdown(audio_html, unsafe_allow_html=True)
        st.markdown(sentences,unsafe_allow_html=True)
        st.session_state["messages"].append({"role": "assistant", "avatar": assistant_avatar,"content": sentences})
        st.audio(audio_bytes_data, format="audio/wav")


# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
def generate_system_prompt(target_language,max_text_count):
    system_prompt=f"""
    ã‚ãªãŸã¯ãšã‚“ã ã‚‚ã‚“ã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«åˆ¶ç´„æ¡ä»¶ã«å¾“ã£ã¦è¦ªåˆ‡ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

    # åˆ¶ç´„æ¡ä»¶
        - çµµæ–‡å­—ã¯ä½¿ã‚ãªã„äº‹ã€‚
        - {max_text_count}æ–‡å­—ä»¥å†…ã§ç­”ãˆã‚‹äº‹ã€‚
        - å›ç­”è¨€èªã§å¿…ãšå›ç­”ã™ã‚‹äº‹ã€‚

    # å›ç­”è¨€èªï¼š{target_language}

    """
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    return  SystemMessage(
                        content=[
                            {
                                "type": "text",
                                "text": system_prompt,
                            },
                        ]
    )


# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
def generate_user_prompt(prompt):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    return HumanMessage(
                    content=[
                            {
                                "type": "text",
                                "text": prompt,
                            },
                        ]
                    )



# ãƒšãƒ¼ã‚¸æ§‹æˆ
st.set_page_config(page_title="ãšã‚“ã ã‚‚ã‚“ ã¡ã‚ƒã£ã¨ with Zundamon Speech",page_icon="ğŸ«›", layout="wide")

# ã‚¿ã‚¤ãƒˆãƒ«
st.markdown("# ğŸ«›ãšã‚“ã ã‚‚ã‚“ ã¡ã‚ƒã£ã¨ with Zundamon Speech", unsafe_allow_html=True)

# ãƒãƒ£ãƒƒãƒˆã®ã‚¢ãƒã‚¿ãƒ¼
user_avatar = "ğŸ˜€"
assistant_avatar = "ğŸ«›"

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚¿ã‚¤ãƒˆãƒ«
st.sidebar.markdown("# ğŸ“ã¡ã‚ƒã£ã¨è¨­å®š")

# LLMãƒ¢ãƒ‡ãƒ«é¸æŠ
st.sidebar.markdown("### ğŸ¤–LLMãƒ¢ãƒ‡ãƒ«")
llm_model = st.sidebar.radio("LLMãƒ¢ãƒ‡ãƒ«é¸æŠã™ã‚‹ã®ã ",["gemini-1.5-flash","gemini-2.0-flash"], index=0)

# ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
st.sidebar.markdown("### ğŸ”Šãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«")
uploaded_audio = st.sidebar.file_uploader("ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã  (WAV, FLAC, MP3)", type=["wav", "flac", "mp3"])

# ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
st.sidebar.markdown("### ğŸ“„ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ")
default_target_text = "æµã—åˆ‡ã‚ŠãŒå®Œå…¨ã«å…¥ã‚Œã°ãƒ‡ãƒãƒ•ã®åŠ¹æœãŒä»˜ä¸ã•ã‚Œã‚‹"
default_ref_text = st.sidebar.text_area("ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã®ã ", value=default_target_text, height=100)

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆå…ƒã®æ‹¡å¼µæ©Ÿèƒ½ã‚’ç¶­æŒï¼‰
if uploaded_audio is not None:
    audio_suffix = os.path.splitext(uploaded_audio.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=audio_suffix) as tmp_audio:
        tmp_audio.write(uploaded_audio.read())
        tmp_audio_path = tmp_audio.name

 # å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
if default_ref_text != "":
    with tempfile.NamedTemporaryFile(delete=False, suffix=".txt", mode='w', encoding='utf-8') as tmp_ref_text:
        tmp_ref_text.write(default_ref_text)
        tmp_ref_text_path = tmp_ref_text.name

# ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºã‚³ãƒ³ãƒ†ãƒŠ
main_container = st.container(height=500)
# ãƒãƒ£ãƒƒãƒˆè¡¨ç¤º
for message in st.session_state["messages"]:
    with main_container.chat_message(name=message["role"],avatar=message["avatar"]):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
        st.markdown(message["content"],unsafe_allow_html=True)

# ãƒœã‚¿ãƒ³ã‚³ãƒ³ãƒ†ãƒŠ
buttons_container = st.container()

# ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
prompt = buttons_container.text_area(label="è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã®ã ",
                                    placeholder="ãšã‚“ã ã‚‚ã‚“ã®äº‹æ•™ãˆã¦",
                                    height=80)

# ã‚«ãƒ©ãƒ ç”Ÿæˆ
lang_selectbox,run_button,blank,new_chat_button = buttons_container.columns([1,1,3,1],vertical_alignment="bottom")


# è¨€èªé¸æŠ
with lang_selectbox:
    target_language = st.selectbox("è¨€èªã‚’é¸æŠã™ã‚‹ã®ã ", ["Japanese",
                                                        "English",
                                                        "Chinese",
                                                        "Cantonese",
                                                        "Korean",])


# ã¡ã‚ƒã£ã¨å®Ÿè¡Œãƒœã‚¿ãƒ³
with run_button:
    if st.button(label="ã¡ã‚ƒã£ã¨å®Ÿè¡Œ",icon="ğŸ’­",type="primary"):
        if prompt == "":
            main_container.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã®ã ",icon="âœ–")
            st.stop()

        if uploaded_audio is None:
            main_container.error("ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã ",icon="âœ–")
            st.stop()

        else:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼
            with main_container.chat_message("user", avatar=user_avatar):
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                system_prompt = generate_system_prompt(target_language,30)
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                user_prompt = generate_user_prompt(prompt)
                # è¡¨ç¤ºç”¨
                st.session_state["messages"].append({"role": "user", "avatar": user_avatar,"content":  prompt})
                st.markdown(prompt,unsafe_allow_html=True)
                # AI
                with main_container.chat_message("assistant", avatar=assistant_avatar):
                    try:
                        with st.spinner(text="ğŸ’­å‡¦ç†ä¸­ãªã®ã ...",show_time=True):
                            # LLMåˆæœŸåŒ–
                            llm = init_llm(llm_model)
                            # LLMå®Ÿè¡Œ
                            response = llm.invoke([system_prompt,user_prompt])
                            # çµæœå–å¾—
                            result = response.content
                            # çµæœã®æ–‡ç« ã‚’æ–‡ç¯€ã”ã¨ã«åˆ†å‰²
                            split_sentences = []
                            if target_language == "Japanese":
                                split_punc2 = functools.partial(split_punctuation,
                                                                punctuations=r"ã€‚!?")
                                concat_tail_te = functools.partial(concatenate_matching,
                                                                   former_matching_rule=r"^(?P<result>.+)(ã¦)$",
                                                                   remove_former_matched=False)
                                segmenter = make_pipeline(normalize,
                                                          split_newline,
                                                          concat_tail_te,
                                                          split_punc2)
                                split_sentences = list(segmenter(result))
                            else:
                                splitter = SentenceSplitter(language='en')
                                split_sentences = splitter.split(text=result)

                            # ãƒ‡ãƒãƒƒã‚°ç”¨
                            print("target_language------------------------------")
                            print(target_language)
                            print("split_sentences------------------------------")
                            print(split_sentences)
                            print("---------------------------------------------")

                            for sentences in split_sentences:
                                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸è¾¼
                                with tempfile.NamedTemporaryFile(delete=False,
                                                                 suffix=".txt",
                                                                 mode='w',
                                                                 encoding='utf-8') as tmp_target_text:
                                    tmp_target_text.write(sentences)
                                    tmp_target_text_path = tmp_target_text.name
                                # ä¸€æ™‚å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                                tmp_output_dir = tempfile.mkdtemp()
                                # æ¨è«–é–¢æ•°ã‚’å‘¼ã³å‡ºã—
                                ref_language = "Japanese"
                                synthesize(tmp_audio_path,
                                            tmp_ref_text_path,
                                            ref_language,
                                            tmp_target_text_path,
                                            target_language,
                                            tmp_output_dir)
                                # æ¨è«–é–¢æ•°ã¯ã€output.wavã¨ã„ã†åå‰ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
                                output_wav_path = os.path.join(tmp_output_dir, "output.wav")
                                if os.path.exists(output_wav_path):
                                    # éŸ³å£°å†ç”Ÿ
                                    play_audio(output_wav_path,assistant_avatar,sentences)
                                else:
                                    st.error("ç”Ÿæˆã«å¤±æ•—ã—ãŸã®ã ",icon="âœ–")
                                    st.stop()

                    except Exception as e:
                        st.error(f"æ¨è«–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸã®ã : {e}",icon="âœ–")
                        st.stop()


# æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆãƒœã‚¿ãƒ³
with new_chat_button:
    if st.button(label="æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆ",icon="ğŸ†•"):
        st.session_state["messages"] = []
        main_container.success("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã«ã—ãŸã®ã ",icon="âœ…")
        time.sleep(1)
        st.rerun()
